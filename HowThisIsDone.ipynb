{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extraordinary-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "binding-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "removed-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nervous-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cheap-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://postgres:mypassword@192.168.1.174/process_text_processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "developing-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_sql(\"\"\"\n",
    "    SELECT \"text\" FROM textdocuments WHERE \"text\" ~ '^[а-яА-Я[:punct:]\\s]+$' OFFSET 1000 LIMIT 1000\n",
    "\"\"\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "challenging-seeker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    1000 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "accepted-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [t.split(\"\\n\") for t in data.text]\n",
    "raw_text = \" \".join(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hired-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "instant-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "following-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(\n",
    "    lower=True,\n",
    "    num_words = 100000\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "colored-helicopter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177274\n"
     ]
    }
   ],
   "source": [
    "print(total_words)\n",
    "total_words = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "demonstrated-purple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# pad sequences \n",
    "# max_sequence_len = max([len(x) for x in input_sequences])\n",
    "max_sequence_len = 40\n",
    "print(max_sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spoken-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = np.array(pad_sequences(input_sequences[:300000], maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictors and label\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(20)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(xs, ys, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"Laurence went to dublin\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "polish-glory",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "established-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fitted-display",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  1120797\n",
      "Total Vocab:  88\n"
     ]
    }
   ],
   "source": [
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "medium-christmas",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1120697/1120697 [00:15<00:00, 70937.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  1120697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in tqdm(range(0, n_chars - seq_length, 1)):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int.get(char, 0) for char in seq_in])\n",
    "    dataY.append(char_to_int.get(seq_out, 0))\n",
    "    \n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "radical-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = tf.keras.utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "virtual-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bigger-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "# filename = \"weights-improvement-19-1.9435.hdf5\"\n",
    "# model.load_weights(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "appointed-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "genuine-rebel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "70431/70431 [==============================] - 6263s 89ms/step - loss: 2.7826\n",
      "Epoch 2/5\n",
      "70431/70431 [==============================] - 6277s 89ms/step - loss: 2.3532\n",
      "Epoch 3/5\n",
      "70431/70431 [==============================] - 6280s 89ms/step - loss: 2.1831\n",
      "Epoch 4/5\n",
      "70431/70431 [==============================] - 6266s 89ms/step - loss: 2.0935\n",
      "Epoch 5/5\n",
      "70431/70431 [==============================] - 6261s 89ms/step - loss: 2.0356\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "objective-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-albert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  671/22414 [..............................] - ETA: 1:28:43 - loss: 1.8995"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=5, verbose=1, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "lyric-socket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" д Киева вынес решение о признании свидетельства на знак для товаров и услуг 'Сбербанк', владельцем к \"\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "satellite-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "composition = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "italian-fossil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    composition += result\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print( \"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "structured-warrant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['в',\n",
       " 'к',\n",
       " 'и',\n",
       " ' ',\n",
       " 'п',\n",
       " 'о',\n",
       " 'с',\n",
       " 'т',\n",
       " 'а',\n",
       " 'в',\n",
       " 'к',\n",
       " 'и',\n",
       " ' ',\n",
       " 'п',\n",
       " 'о',\n",
       " 'с',\n",
       " 'т',\n",
       " 'а',\n",
       " 'в',\n",
       " 'к',\n",
       " 'и',\n",
       " ' ',\n",
       " 'п',\n",
       " 'о',\n",
       " 'с',\n",
       " 'т',\n",
       " 'а',\n",
       " 'в',\n",
       " 'к',\n",
       " 'и',\n",
       " ' ',\n",
       " 'п',\n",
       " 'о',\n",
       " 'с',\n",
       " 'т',\n",
       " 'а',\n",
       " 'в',\n",
       " 'к',\n",
       " 'и',\n",
       " ' ',\n",
       " 'п',\n",
       " 'о',\n",
       " 'с',\n",
       " 'т',\n",
       " 'а',\n",
       " 'в',\n",
       " 'к',\n",
       " 'и',\n",
       " ' ',\n",
       " 'п',\n",
       " 'о',\n",
       " 'с',\n",
       " 'т',\n",
       " 'а',\n",
       " 'в',\n",
       " 'к',\n",
       " 'и',\n",
       " ' ',\n",
       " 'п',\n",
       " 'о',\n",
       " 'с',\n",
       " 'т',\n",
       " 'а',\n",
       " 'в',\n",
       " 'к',\n",
       " 'и',\n",
       " ' ',\n",
       " 'п',\n",
       " 'о',\n",
       " 'с',\n",
       " 'т',\n",
       " 'а',\n",
       " 'в',\n",
       " 'к',\n",
       " 'и',\n",
       " ' ',\n",
       " 'п',\n",
       " 'о',\n",
       " 'с',\n",
       " 'т',\n",
       " 'а',\n",
       " 'в',\n",
       " 'к',\n",
       " 'и',\n",
       " ' ',\n",
       " 'п',\n",
       " 'о',\n",
       " 'с',\n",
       " 'т',\n",
       " 'а',\n",
       " 'в',\n",
       " 'к',\n",
       " 'и',\n",
       " ' ',\n",
       " 'п',\n",
       " 'о',\n",
       " 'с',\n",
       " 'т',\n",
       " 'а',\n",
       " 'в']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "material-container",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ак поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставки поставк'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-screening",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
