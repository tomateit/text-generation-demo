{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca27c59f",
   "metadata": {},
   "source": [
    "# Генерация текста с помощью LSTM-сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b8d5d3",
   "metadata": {},
   "source": [
    "Сеть способна выучить распределение символов в последовательностях\n",
    "\n",
    "\n",
    "Датасет формируем проходясь окном по текстовому корпусу, задача сети - предсказывать следующий символ на основании нескольких предыдущих.\n",
    "Данный подход можно улучшить, используя только отдельные предложения с паддингами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "98b8dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2dc1c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952945b6",
   "metadata": {},
   "source": [
    "### 0. Получение данных для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e7d77c",
   "metadata": {},
   "source": [
    "Для обучения используется датасет российских новостей, который был сохранён в файл `text_corpus.parquet` со следующими параметрами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f159d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_parquet(\"text_corpus.parquet\", engine=\"pyarrow\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ffcfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"text_corpus.parquet\", engine=\"pyarrow\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66fb18f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b77e4e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# после обучения токенизатора можно уменьшить тренировочную выборку\n",
    "# но нужно не забыть обновить переменную corpus\n",
    "data = data.sample(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32701f7",
   "metadata": {},
   "source": [
    "### 1. Вспомогательные функции:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0c53fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f30f828",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# весь текст одной \"портянкой\", чтобы заранее оценить, какие символы могут нам попадаться\n",
    "# raw_text = \" \".join(data.text)\n",
    "# chars = sorted(list(set(raw_text)))\n",
    "# chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd77197",
   "metadata": {},
   "source": [
    "### 3. Предобработка и создание датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e5ceb7",
   "metadata": {},
   "source": [
    "Для тренировки LSTM модели понадобится немного поработать с форматами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b33b534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e99a6621",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \" \\n\".join(data.text.to_list()).lower()\n",
    "# Хочу отделить всю пунктуацию от слов пробелом\n",
    "corpus = \" \".join(re.findall(r\"[\\w']+|[.,!?;\\n]\", corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3545a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = 800\n",
    "max_sequence_length = 80\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2582f92",
   "metadata": {},
   "source": [
    "#### 3.1 Токенизация BPE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4518b3a7",
   "metadata": {},
   "source": [
    "BPE токенизация посредством yttm эффективна, но потребуется поработать с файлом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "367835e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import youtokentome as yttm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47683b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_model_path = \"bpe.yttm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd3cddf",
   "metadata": {},
   "source": [
    "##### 3.2 Создаём токенизатор BPE и обучаем его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47ff5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bpe_tokenizer_from_scratch(corpus, train_data_path=\"yttm_train_data.txt\"):\n",
    "    with open(train_data_path, \"w\") as _file:\n",
    "        _file.writelines(corpus)\n",
    "    # Training model\n",
    "    # (data, model, vocab_size, coverage, n_threads=-1, pad_id=0, unk_id=1, bos_id=2, eos_id=3)\n",
    "    return yttm.BPE.train(data=train_data_path, vocab_size=total_words, model=bpe_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc51adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model\n",
    "bpe = create_bpe_tokenizer_from_scratch(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa89f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "bpe = yttm.BPE(model=bpe_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c92cb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> <UNK> <BOS> <EOS> ▁ о е и а н т с р в л к п д м у я ы г з б , ь ч й . х ж ' ц ю ш ф щ э ъ ? ё ! ; _ ▁п ▁с ▁в ▁, ст ни ра ро но ре на ▁о ко то ▁. ▁и ▁по го не де те ли ва ▁м за ны ▁на ль ка ри та ле ла ▁д во ве ▁б ти ци ▁со ви ▁ч ки ло ▁у ▁за ▁' да ть ен ми ▁а ▁не ▁ко сс ▁пре ет ру ся ди ▁про н\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(bpe.vocab())[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "277ba0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode(self, \n",
    "#     sentences, \n",
    "#     output_type=yttm.OutputType.ID, \n",
    "#     bos=False, \n",
    "#     eos=False, \n",
    "#     reverse=False, \n",
    "#     dropout_prob=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "031eaab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_corpus = np.array(bpe.encode(corpus))\n",
    "\n",
    "# sequences = sequence[:-(len(sequence)%max_sequence_length)].reshape((len(sequence)//max_sequence_length, max_sequence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fd31813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9dfaa696",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encoded_corpus, sequence_length=80):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.n_samples = encoded_corpus.shape[0] - max_sequence_length - 1\n",
    "        self.X = torch.from_numpy(encoded_corpus)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index : index+self.sequence_length], self.X[index+self.sequence_length + 1].view((1))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a384940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextDataset(encoded_corpus, sequence_length=max_sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f691bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1b866ce",
   "metadata": {},
   "source": [
    "## 4. Модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dc75b5",
   "metadata": {},
   "source": [
    "В качестве модели будет применяться LSTM сеть с двумя слоями LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fd7f98",
   "metadata": {},
   "source": [
    "TODO\n",
    "+ Gradient clipping\n",
    "+ More layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "796bec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_size=max_sequence_length,\n",
    "            num_classes=total_words,\n",
    "            hidden_dim=64,\n",
    "            num_layers=2,\n",
    "            batch_size=128,\n",
    "                ):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(self.num_classes, self.hidden_dim, padding_idx=0)\n",
    "        # Bi-LSTM\n",
    "        # Forward and backward\n",
    "        self.lstm_cell_forward = nn.LSTMCell(self.hidden_dim, self.hidden_dim)\n",
    "        self.lstm_cell_backward = nn.LSTMCell(self.hidden_dim, self.hidden_dim)\n",
    "        # LSTM layer\n",
    "        self.lstm_cell = nn.LSTMCell(self.hidden_dim * 2, self.hidden_dim * 2)\n",
    "        \n",
    "#         self.lstm = nn.LSTM(\n",
    "#             max_input_length,  # input_size – The number of expected features in the input x\n",
    "#             hidden_dim, # hidden_size – The number of features in the hidden state h\n",
    "#             num_layers, # num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1\n",
    "#             # bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    "#             batch_first=True# batch_first – If True, then the input and output tensors are provided as (batch, seq, feature). Default: False\n",
    "#             # dropout – If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "#             bidirectional=True# bidirectional – If True, becomes a bidirectional LSTM. Default: False\n",
    "#             # proj_size – If > 0, will use LSTM with projections of corresponding size. Default: 0\n",
    "#         )\n",
    "        \n",
    "        self.linear = nn.Linear(self.hidden_dim * 2, self.num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Bi-LSTM\n",
    "        # hs = [batch_size x hidden_size]\n",
    "        # cs = [batch_size x hidden_size]\n",
    "        hs_forward = torch.zeros(X.size(0), self.hidden_dim)\n",
    "        cs_forward = torch.zeros(X.size(0), self.hidden_dim)\n",
    "        hs_backward = torch.zeros(X.size(0), self.hidden_dim)\n",
    "        cs_backward = torch.zeros(X.size(0), self.hidden_dim)\n",
    "\n",
    "        # LSTM\n",
    "        # hs = [batch_size x (hidden_size * 2)]\n",
    "        # cs = [batch_size x (hidden_size * 2)]\n",
    "        hs_lstm = torch.zeros(X.size(0), self.hidden_dim * 2)\n",
    "        cs_lstm = torch.zeros(X.size(0), self.hidden_dim * 2)\n",
    "\n",
    "        # Weights initialization\n",
    "        torch.nn.init.kaiming_normal_(hs_forward)\n",
    "        torch.nn.init.kaiming_normal_(cs_forward)\n",
    "        torch.nn.init.kaiming_normal_(hs_backward)\n",
    "        torch.nn.init.kaiming_normal_(cs_backward)\n",
    "        torch.nn.init.kaiming_normal_(hs_lstm)\n",
    "        torch.nn.init.kaiming_normal_(cs_lstm)\n",
    "\n",
    "        # From idx to embedding\n",
    "        out = self.embedding(X) \n",
    "#         print(f\"Embedding output shape: {out.shape}\") # [20,80,64]\n",
    "        # Prepare the shape for LSTM Cells\n",
    "        # out = out.view(self.sequence_len, X.size(0), -1)\n",
    "        \n",
    "        \n",
    "        forward = []\n",
    "        backward = []\n",
    "\n",
    "        # Unfolding Bi-LSTM\n",
    "        # Forward\n",
    "        for i in range(self.input_size):\n",
    "            hs_forward, cs_forward = self.lstm_cell_forward(out[:, i], (hs_forward, cs_forward))\n",
    "            hs_forward = self.dropout(hs_forward)\n",
    "            cs_forward = self.dropout(cs_forward)\n",
    "            forward.append(hs_forward)\n",
    "\n",
    "         # Backward\n",
    "        for i in reversed(range(self.input_size)):\n",
    "            hs_backward, cs_backward = self.lstm_cell_backward(out[:, i], (hs_backward, cs_backward))\n",
    "            hs_backward = self.dropout(hs_backward)\n",
    "            cs_backward = self.dropout(cs_backward)\n",
    "            backward.append(hs_backward)\n",
    "            \n",
    "            \n",
    "         # LSTM\n",
    "        for fwd, bwd in zip(forward, backward):\n",
    "            input_tensor = torch.cat((fwd, bwd), 1)\n",
    "            hs_lstm, cs_lstm = self.lstm_cell(input_tensor, (hs_lstm, cs_lstm))\n",
    "\n",
    "         # Last hidden state is passed through a linear layer\n",
    "        out = self.linear(hs_lstm)\n",
    "#         print(f\"Linear input shape: {hs_lstm.shape}\") [20, 128]\n",
    "#         print(f\"Linear output shape: {out.shape}\") [20, 800]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2d66118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "num_epochs = 1\n",
    "batch_size = 64\n",
    "num_batches = int(len(dataset) / batch_size)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "# Model initialization\n",
    "model = LSTMModel(\n",
    "            input_size=max_sequence_length,\n",
    "            num_classes=total_words,\n",
    "            hidden_dim=80,\n",
    "            num_layers=2,\n",
    "            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b071d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(dataloader))\n",
    "y_ = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0e76ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/48120 [00:00<5:37:09,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68214 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1001/48120 [04:27<3:16:18,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 5.87584 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2001/48120 [08:56<3:07:43,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.06271 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3001/48120 [13:38<4:16:34,  2.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 5.91479 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4001/48120 [19:51<6:01:29,  2.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 5.99771 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5001/48120 [27:23<4:06:41,  2.91it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 5.93749 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 5726/48120 [36:00<3:47:29,  3.11it/s] "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "loss_history = []\n",
    "# Training pahse\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Mini batches\n",
    "    for i, (X, y) in tqdm(enumerate(dataloader), total=num_batches):\n",
    "        # Feed the model\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # Loss calculation\n",
    "        loss = F.cross_entropy(y_pred, y.squeeze())\n",
    "        loss_history.append(loss.item())\n",
    "        \n",
    "        # Clean gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Calculate gradientes\n",
    "        loss.backward()\n",
    "\n",
    "        # Updated parameters\n",
    "        optimizer.step()\n",
    "        if not bool(i%1000):\n",
    "            print(\"Epoch: %d ,  loss: %.5f \" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6dea151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "torch.save(model.state_dict(), \"./lstm__model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9c19ade1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3e4b363b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd618e66220>]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0355acdb",
   "metadata": {},
   "source": [
    "## 5. Инференс полученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "38c2e004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern:\n",
      "сообщил , что кремль начал планомерную работу по дискредитации навального . якобы решение спровоцировали фильм фбк он вам не димон и прошедшие по всей стране митинги , снизившие рейтинг премьер министра дмитрия \n",
      "\n",
      "Prediction:\n",
      "сообщил , что кремль начал планомерную работу по дискредитации навального . якобы решение спровоцировали фильм фбк он вам не димон и прошедшие по всей стране митинги , снизившие рейтинг премьер министра дмитрия . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_tokens = 400\n",
    "# Set the model in evalulation mode\n",
    "model.eval()\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "start = np.random.randint(0, len(dataset))\n",
    "pattern, _ = dataset[start]\n",
    "full_prediction = pattern.tolist()\n",
    "\n",
    "print(\"Pattern:\")\n",
    "print(bpe.decode(full_prediction)[0], \"\\n\")\n",
    "\n",
    "for i in range(n_tokens):\n",
    "    pattern = torch.tensor(full_prediction[:80]).view((1,-1))\n",
    "    prediction = model(pattern)\n",
    "    prediction = softmax(prediction)\n",
    "\n",
    "    arg_max = torch.argmax(prediction).item()\n",
    "    full_prediction.append(arg_max)\n",
    "\n",
    "print(\"Prediction:\")\n",
    "print(bpe.decode(full_prediction)[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b4c2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_generation",
   "language": "python",
   "name": "text_generation_demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
