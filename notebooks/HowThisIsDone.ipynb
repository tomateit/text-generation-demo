{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84c8b7e7",
   "metadata": {},
   "source": [
    "# Генерация текста с помощью LSTM-сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7ff46",
   "metadata": {},
   "source": [
    "Сеть способна выучить распределение символов в последовательностях\n",
    "\n",
    "\n",
    "Датасет формируем проходясь окном по текстовому корпусу, задача сети - предсказывать следующий символ на основании нескольких предыдущих.\n",
    "Данный подход можно улучшить, используя только отдельные предложения с паддингами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fa661bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61dc9980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f360aa54",
   "metadata": {},
   "source": [
    "### 0. Получение данных для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a723e5",
   "metadata": {},
   "source": [
    "Для обучения используется датасет российских новостей, который был сохранён в файл `text_corpus.parquet` со следующими параметрами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e52cff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_parquet(\"text_corpus.parquet\", engine=\"pyarrow\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bef7cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"text_corpus.parquet\", engine=\"pyarrow\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a30ffcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44adc5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# после обучения токенизатора можно уменьшить тренировочную выборку\n",
    "# но нужно не забыть обновить переменную corpus\n",
    "data = data.sample(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476054c2",
   "metadata": {},
   "source": [
    "### 1. Вспомогательные функции:\n",
    "+ Визуализация процесса обучения\n",
    "    + Сможем посмотреть, как меняется качество с течением времени.\n",
    "+ Коллбек ModelCheckpoint\n",
    "    + Процесс обучения LSTM сетей достаточно длительный. Будет обидно, если из-за непредвиденного сбоя потеряется прогресс за многие часы обучения.\n",
    "+ Колбек динамической подстройки размера батча и learning rate\n",
    "    + Подстраивать LR это уже стандартная практика, а я хочу ещё и размер батча менять: предположу, что большой батч позволит дать некое \"обобщённое\" представление о распределении токенов, а маленький батч улучшит \"грамотность\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c820d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5bf6966",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# весь текст одной \"портянкой\", чтобы заранее оценить, какие символы могут нам попадаться\n",
    "# raw_text = \" \".join(data.text)\n",
    "# chars = sorted(list(set(raw_text)))\n",
    "# chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659c8075",
   "metadata": {},
   "source": [
    "### 3. Предобработка и создание датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29a9032",
   "metadata": {},
   "source": [
    "Для тренировки LSTM модели понадобится немного поработать с форматами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6945df03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afef23cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \" \\n\".join(data.text.to_list()).lower()\n",
    "# Хочу отделить всю пунктуацию от слов пробелом\n",
    "corpus = \" \".join(re.findall(r\"[\\w']+|[.,!?;\\n]\", corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "343808a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = 800\n",
    "max_sequence_length = 80\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3578a7a6",
   "metadata": {},
   "source": [
    "#### 3.1 Токенизация BPE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce28a09e",
   "metadata": {},
   "source": [
    "BPE токенизация посредством yttm эффективна, но потребуется поработать с файлом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "370a7c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import youtokentome as yttm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d5268ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_model_path = \"bpe.yttm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b788808d",
   "metadata": {},
   "source": [
    "##### 3.2 Создаём токенизатор BPE и обучаем его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee8175c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bpe_tokenizer_from_scratch(corpus, train_data_path=\"yttm_train_data.txt\"):\n",
    "    with open(train_data_path, \"w\") as _file:\n",
    "        _file.writelines(corpus)\n",
    "    # Training model\n",
    "    # (data, model, vocab_size, coverage, n_threads=-1, pad_id=0, unk_id=1, bos_id=2, eos_id=3)\n",
    "    return yttm.BPE.train(data=train_data_path, vocab_size=total_words, model=bpe_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbfc7463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model\n",
    "bpe = create_bpe_tokenizer_from_scratch(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3f39f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "bpe = yttm.BPE(model=bpe_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ad39ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> <UNK> <BOS> <EOS> ▁ о е и а н т с р в л к п д м у я ы г з б , ь ч й . х ж ' ц ю ш ф щ э ъ ? ё ! ; _ ▁п ▁с ▁в ▁, ст ни ра ро но ре на ▁о ко то ▁. ▁и ▁по го не де те ли ва ▁м за ны ▁на ль ка ри та ле ла ▁д во ве ▁б ти ци ▁со ви ▁ч ки ло ▁у ▁за ▁' да ть ен ми ▁а ▁не ▁ко сс ▁пре ет ру ся ди ▁про н\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(bpe.vocab())[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "36352f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode(self, \n",
    "#     sentences, \n",
    "#     output_type=yttm.OutputType.ID, \n",
    "#     bos=False, \n",
    "#     eos=False, \n",
    "#     reverse=False, \n",
    "#     dropout_prob=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38a476c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_corpus = np.array(bpe.encode(corpus))\n",
    "\n",
    "# sequences = sequence[:-(len(sequence)%max_sequence_length)].reshape((len(sequence)//max_sequence_length, max_sequence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8325d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "286f548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encoded_corpus, sequence_length=80):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.n_samples = encoded_corpus.shape[0]-max_sequence_length\n",
    "        self.X = torch.from_numpy(encoded_corpus)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index : index+self.sequence_length], self.X[index+self.sequence_length + 1].view((1))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd51ca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextDataset(encoded_corpus, sequence_length=max_sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e535b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbb7b302",
   "metadata": {},
   "source": [
    "## 4. Модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b55b6c9",
   "metadata": {},
   "source": [
    "В качестве модели будет применяться LSTM сеть с двумя слоями LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918c417f",
   "metadata": {},
   "source": [
    "TODO\n",
    "+ Gradient clipping\n",
    "+ More layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "11779f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_size=max_sequence_length,\n",
    "            num_classes=total_words,\n",
    "            hidden_dim=64,\n",
    "            num_layers=2,\n",
    "            batch_size=128,\n",
    "                ):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(self.num_classes, self.hidden_dim, padding_idx=0)\n",
    "        # Bi-LSTM\n",
    "        # Forward and backward\n",
    "        self.lstm_cell_forward = nn.LSTMCell(self.hidden_dim, self.hidden_dim)\n",
    "        self.lstm_cell_backward = nn.LSTMCell(self.hidden_dim, self.hidden_dim)\n",
    "        # LSTM layer\n",
    "        self.lstm_cell = nn.LSTMCell(self.hidden_dim * 2, self.hidden_dim * 2)\n",
    "        \n",
    "#         self.lstm = nn.LSTM(\n",
    "#             max_input_length,  # input_size – The number of expected features in the input x\n",
    "#             hidden_dim, # hidden_size – The number of features in the hidden state h\n",
    "#             num_layers, # num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1\n",
    "#             # bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    "#             batch_first=True# batch_first – If True, then the input and output tensors are provided as (batch, seq, feature). Default: False\n",
    "#             # dropout – If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "#             bidirectional=True# bidirectional – If True, becomes a bidirectional LSTM. Default: False\n",
    "#             # proj_size – If > 0, will use LSTM with projections of corresponding size. Default: 0\n",
    "#         )\n",
    "        \n",
    "        self.linear = nn.Linear(self.hidden_dim * 2, self.num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Bi-LSTM\n",
    "        # hs = [batch_size x hidden_size]\n",
    "        # cs = [batch_size x hidden_size]\n",
    "        hs_forward = torch.zeros(X.size(0), self.hidden_dim)\n",
    "        cs_forward = torch.zeros(X.size(0), self.hidden_dim)\n",
    "        hs_backward = torch.zeros(X.size(0), self.hidden_dim)\n",
    "        cs_backward = torch.zeros(X.size(0), self.hidden_dim)\n",
    "\n",
    "        # LSTM\n",
    "        # hs = [batch_size x (hidden_size * 2)]\n",
    "        # cs = [batch_size x (hidden_size * 2)]\n",
    "        hs_lstm = torch.zeros(X.size(0), self.hidden_dim * 2)\n",
    "        cs_lstm = torch.zeros(X.size(0), self.hidden_dim * 2)\n",
    "\n",
    "        # Weights initialization\n",
    "        torch.nn.init.kaiming_normal_(hs_forward)\n",
    "        torch.nn.init.kaiming_normal_(cs_forward)\n",
    "        torch.nn.init.kaiming_normal_(hs_backward)\n",
    "        torch.nn.init.kaiming_normal_(cs_backward)\n",
    "        torch.nn.init.kaiming_normal_(hs_lstm)\n",
    "        torch.nn.init.kaiming_normal_(cs_lstm)\n",
    "\n",
    "        # From idx to embedding\n",
    "        out = self.embedding(X) \n",
    "#         print(f\"Embedding output shape: {out.shape}\") # [20,80,64]\n",
    "        # Prepare the shape for LSTM Cells\n",
    "        # out = out.view(self.sequence_len, X.size(0), -1)\n",
    "        \n",
    "        \n",
    "        forward = []\n",
    "        backward = []\n",
    "\n",
    "        # Unfolding Bi-LSTM\n",
    "        # Forward\n",
    "        for i in range(self.input_size):\n",
    "            hs_forward, cs_forward = self.lstm_cell_forward(out[:, i], (hs_forward, cs_forward))\n",
    "            hs_forward = self.dropout(hs_forward)\n",
    "            cs_forward = self.dropout(cs_forward)\n",
    "            forward.append(hs_forward)\n",
    "\n",
    "         # Backward\n",
    "        for i in reversed(range(self.input_size)):\n",
    "            hs_backward, cs_backward = self.lstm_cell_backward(out[:, i], (hs_backward, cs_backward))\n",
    "            hs_backward = self.dropout(hs_backward)\n",
    "            cs_backward = self.dropout(cs_backward)\n",
    "            backward.append(hs_backward)\n",
    "            \n",
    "            \n",
    "         # LSTM\n",
    "        for fwd, bwd in zip(forward, backward):\n",
    "            input_tensor = torch.cat((fwd, bwd), 1)\n",
    "            hs_lstm, cs_lstm = self.lstm_cell(input_tensor, (hs_lstm, cs_lstm))\n",
    "\n",
    "         # Last hidden state is passed through a linear layer\n",
    "        out = self.linear(hs_lstm)\n",
    "#         print(f\"Linear input shape: {hs_lstm.shape}\") [20, 128]\n",
    "#         print(f\"Linear output shape: {out.shape}\") [20, 800]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "597db777",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "num_epochs = 1\n",
    "num_batches = int(len(dataset) / batch_size)\n",
    "batch_size=200\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "# Model initialization\n",
    "model = LSTMModel(\n",
    "            input_size=max_sequence_length,\n",
    "            num_classes=total_words,\n",
    "            hidden_dim=64,\n",
    "            num_layers=2,\n",
    "            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8f9aa564",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(dataloader))\n",
    "y_ = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d4144994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/153987 [00:00<25:03:43,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68149 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/153987 [00:01<21:59:45,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67743 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/153987 [00:01<20:49:47,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68391 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/153987 [00:01<19:45:26,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67764 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/153987 [00:02<18:59:03,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68883 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/153987 [00:02<18:52:48,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68083 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/153987 [00:03<20:29:29,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68436 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/153987 [00:03<19:45:01,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68712 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/153987 [00:04<19:45:37,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67680 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/153987 [00:04<19:32:33,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67562 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/153987 [00:05<19:38:55,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67980 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/153987 [00:05<23:09:57,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68308 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/153987 [00:06<24:58:34,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67751 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/153987 [00:07<24:24:33,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68549 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/153987 [00:07<22:21:09,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.69014 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/153987 [00:07<22:01:12,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68752 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 17/153987 [00:08<20:57:05,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.69177 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/153987 [00:09<23:29:51,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68762 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 19/153987 [00:09<22:56:54,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68187 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/153987 [00:10<21:34:24,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67969 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/153987 [00:10<22:11:25,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 22/153987 [00:11<23:04:22,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68725 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 23/153987 [00:11<23:07:44,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68889 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 24/153987 [00:12<21:59:14,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68028 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 25/153987 [00:13<26:02:09,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 26/153987 [00:13<25:06:03,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67841 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 27/153987 [00:13<22:53:14,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68118 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 28/153987 [00:14<21:33:53,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68327 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 29/153987 [00:14<21:06:08,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68198 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/153987 [00:15<21:18:37,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68240 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 31/153987 [00:15<20:52:53,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.69246 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 32/153987 [00:16<20:51:55,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68295 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 33/153987 [00:16<20:04:27,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68039 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 34/153987 [00:17<19:17:08,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68486 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 35/153987 [00:17<18:40:50,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.69505 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 36/153987 [00:17<18:21:52,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67902 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 37/153987 [00:18<19:56:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68619 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 38/153987 [00:18<19:11:25,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68533 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 39/153987 [00:19<19:56:55,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68184 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 40/153987 [00:19<19:05:44,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67284 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 41/153987 [00:20<19:07:26,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67223 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 42/153987 [00:21<23:13:44,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68036 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 43/153987 [00:21<23:48:30,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68259 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 44/153987 [00:22<21:53:41,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67310 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 45/153987 [00:22<24:40:02,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67790 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 46/153987 [00:23<22:39:16,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67803 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 47/153987 [00:23<21:08:31,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68661 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 48/153987 [00:24<23:28:56,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67695 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 49/153987 [00:25<25:58:13,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67843 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 50/153987 [00:25<29:56:36,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67896 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 51/153987 [00:26<28:01:38,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67446 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 52/153987 [00:26<25:06:33,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68596 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 53/153987 [00:27<24:01:11,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68230 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 54/153987 [00:27<22:50:15,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67542 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 55/153987 [00:28<23:33:23,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68294 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 56/153987 [00:29<25:14:21,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67939 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 57/153987 [00:29<27:03:19,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68044 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 58/153987 [00:30<25:14:57,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68826 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 59/153987 [00:30<23:43:19,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68121 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 60/153987 [00:31<23:13:59,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67123 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 61/153987 [00:31<23:50:18,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67732 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 62/153987 [00:32<24:42:26,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67387 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 63/153987 [00:33<25:11:54,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67818 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 64/153987 [00:33<24:16:56,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67644 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 65/153987 [00:34<23:49:24,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67270 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 66/153987 [00:34<22:51:27,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68142 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 67/153987 [00:35<21:56:58,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68029 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 68/153987 [00:35<20:56:02,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67054 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 69/153987 [00:36<23:14:40,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67719 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 70/153987 [00:36<22:38:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67953 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 71/153987 [00:37<21:13:52,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67127 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 72/153987 [00:37<21:01:03,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67767 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 73/153987 [00:38<20:02:58,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67984 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 74/153987 [00:38<24:23:45,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68615 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 75/153987 [00:39<27:02:24,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67699 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 76/153987 [00:40<27:27:07,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67757 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 77/153987 [00:41<34:26:08,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67669 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 78/153987 [00:42<30:48:18,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67970 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 79/153987 [00:42<27:19:46,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67105 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 80/153987 [00:43<25:37:37,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.67617 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 81/153987 [00:43<23:59:38,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.68061 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 82/153987 [00:44<22:58:25,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,  loss: 6.66734 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-a49fa93ced9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Feed the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Loss calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/python-playground/app_lstm_text_generation_demo/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-37fb85a75fa0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mhs_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcs_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_cell_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhs_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcs_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mhs_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mcs_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/python-playground/app_lstm_text_generation_demo/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/python-playground/app_lstm_text_generation_demo/.venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'[0]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'[1]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m         return _VF.lstm_cell(\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "loss_history = []\n",
    "# Training pahse\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Mini batches\n",
    "    for i, (X, y) in tqdm(enumerate(dataloader), total=num_batches):\n",
    "        # Feed the model\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # Loss calculation\n",
    "        loss = F.cross_entropy(y_pred, y.squeeze())\n",
    "\n",
    "        # Clean gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Calculate gradientes\n",
    "        loss.backward()\n",
    "\n",
    "        # Updated parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"Epoch: %d ,  loss: %.5f \" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2d56b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "torch.save(model.state_dict(), 'weights/lstm__model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83dfcd4",
   "metadata": {},
   "source": [
    "## 5. Инференс полученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1fe6e019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "приветствие затянулось на несколько вродители,\n",
      "им зае призиденторта согорами в сосесуми рроведе с сосрийской ке просева об пнобо с общела он вобороднтое влодедать в инсотия чесьдае в сосрий сазорунотти в соссий сакали проведа пода саков\n"
     ]
    }
   ],
   "source": [
    "def generator(model, sequences, idx_to_char, n_chars):\n",
    "  \n",
    "    # Set the model in evalulation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Define the softmax function\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    # Randomly is selected the index from the set of sequences\n",
    "    start = np.random.randint(0, len(sequences)-1)\n",
    "\n",
    "    # The pattern is defined given the random idx\n",
    "    pattern = sequences[start]\n",
    "\n",
    "    # By making use of the dictionaries, it is printed the pattern\n",
    "    print(\"\\nPattern: \\n\")\n",
    "    print(''.join([idx_to_char[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "    # In full_prediction we will save the complete prediction\n",
    "    full_prediction = pattern.copy()\n",
    "\n",
    "    # The prediction starts, it is going to be predicted a given\n",
    "    # number of characters\n",
    "    for i in range(n_chars):\n",
    "\n",
    "        # The numpy patterns is transformed into a tesor-type and reshaped\n",
    "        pattern = torch.from_numpy(pattern).type(torch.LongTensor)\n",
    "        pattern = pattern.view(1,-1)\n",
    "\n",
    "        # Make a prediction given the pattern\n",
    "        prediction = model(pattern)\n",
    "        # It is applied the softmax function to the predicted tensor\n",
    "        prediction = softmax(prediction)\n",
    "\n",
    "        # The prediction tensor is transformed into a numpy array\n",
    "        prediction = prediction.squeeze().detach().numpy()\n",
    "        # It is taken the idx with the highest probability\n",
    "        arg_max = np.argmax(prediction)\n",
    "\n",
    "        # The current pattern tensor is transformed into numpy array\n",
    "        pattern = pattern.squeeze().detach().numpy()\n",
    "        # The window is sliced 1 character to the right\n",
    "        pattern = pattern[1:]\n",
    "        # The new pattern is composed by the \"old\" pattern + the predicted character\n",
    "        pattern = np.append(pattern, arg_max)\n",
    "\n",
    "        # The full prediction is saved\n",
    "        full_prediction = np.append(full_prediction, arg_max)\n",
    "\n",
    "    print(\"Prediction: \\n\")\n",
    "    print(''.join([idx_to_char[value] for value in full_prediction]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6cde41c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PAD>']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69da369b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"не планирует передислоцировать наблюдательные пункты в идлибской зоне деэскалации , при этом турция продолжит отправлять военных и бронетехнику в этот район 'в целях защиты мирного населения' . ка\"]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.decode([list(X[522].reshape((max_sequence_length-1)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96638cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "не планирует передислоцировать наблюдательные пункты в идлибской зоне деэскалации , при этом турция продолжит отправлять военных и бронетехнику в этот район 'в целях защиты мирного населения' . ка,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n"
     ]
    }
   ],
   "source": [
    "# Для bpe\n",
    "composition = \"не планирует передислоцировать наблюдательные пункты в идлибской зоне деэскалации , при этом турция продолжит отправлять военных и бронетехнику в этот район 'в целях защиты мирного населения' . ка\"\n",
    "next_words = 200\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = bpe.encode(composition)\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre', truncating=\"pre\")\n",
    "    token_list = token_list.reshape((1,max_sequence_length-1,1))\n",
    "    predicted = np.argmax(model2.predict(token_list), axis=-1)\n",
    "    output_character = bpe.decode([predicted])[0]\n",
    "    composition += output_character\n",
    "print(composition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0db192e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[126, 341, 322, 6, 90, 10, 20, 156, 603, 71, 97, 109, 448]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.encode([\"приветствие затянулось на несколько \"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6bc990ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8dd7ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_ordered_indices(ar):\n",
    "    d = {i:v for i,v in enumerate(ar)}\n",
    "    return sorted(d, key=d.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eefb3746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensures always sums to 1\n",
    "def normalize_softmax(ar):\n",
    "    s = sum(ar)\n",
    "    if (s!=1):\n",
    "        ar[0] += 1-s\n",
    "    return ar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ff4edfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "как было сказано осенее с онкет пантоти и ресетиеее ес о осессон в паттеле онти портовония сакомо презедлитеви презисселе нерари соргорам сосриий,\n",
      "подономо по накраветения подоваи полодать по накогния сообщал возении,\n"
     ]
    }
   ],
   "source": [
    "composition = \"как было сказано \"\n",
    "next_words = 200\n",
    "T = 2 # токены из top-T будут случайно выбираться\n",
    "temperature = 1 # параметр сглаживания распределения выбранных токенов\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([composition])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=window_length-1, padding='pre')\n",
    "    token_list = token_list.reshape((1,window_length-1,1))\n",
    "    \n",
    "    output = model2.predict(token_list)\n",
    "    topmost_indicies = return_ordered_indices(output[0, :])[:T]\n",
    "    probs = tf.nn.softmax(output[0, topmost_indicies] /  temperature).numpy()\n",
    "    probs = normalize_softmax(probs)\n",
    "    predicted = np.random.choice(topmost_indicies, p=probs)\n",
    "#     predicted = topmost_indicies[0]\n",
    "    output_character = tokenizer.sequences_to_texts([[predicted]])[0]\n",
    "    composition += output_character\n",
    "print(composition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d46c0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_generation",
   "language": "python",
   "name": "text_generation_demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
